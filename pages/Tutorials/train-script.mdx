# Train Script and Code Migration

You are now ready to start writing code to begin training your model. Start off by writing all training related scripts in
the `TrainScript.py` file.

## Config

A config isn't a special yaml file which a user has to declare rather it's a set of hyperparameters you wish to track with
your model. These hyperparameters will be displayed for you on the Bench AI site, so you know exactly what parameters gave you
those amazing results! In further examples you will see that configs will be passed in as dictionary's to accelerators and trackers
to start the monitoring process!

## Hugging Face Accelerate

Bench AI offers users top of the line servers, in various different configurations.
Users can train their models on up to 8 gpu's, however to fully utilize these configurations requires the use of
distributed training libraries.

`bench-kit` directly integrates with Hugging Face Accelerate allowing users to train their models on distributed systems
without needing to change most of their code.

Hugging Face Accelerate provides integrations with various model trackers, allowing users to use their favorite
trackers such as TensorBoard right out of the box. Hugging Face Accelerate also provides in depth features that allows users to optimize their distributed training pipeline. All of which can be found in
the [Accelerate docs ↗](https://huggingface.co/docs/accelerate/index).

For the rest of the section the essentials of what's needed to turn your regular Pytorch training script into an
Accelerate compatible script will be displayed.

### `Accelerator`
The Accelerator is the main focal point for the Hugging Face accelerate API. It does all the heavy lifting of gpu synchronization
and distributed operations for the user.

#### `Prepare`
Any objects that are to be used in the training process should be passed into the `Accelerator.prepare()` method, this signals
to the Accelerator API that these objects will be directly used in the training process.

Objects that are generally passed into this method are:
- dataloaders
- models
- optimizers
- schedulers

```python filename="TrainScript.py" copy
from accelerate import Accelerator
import torch.nn as nn
import torch.optim as opt
from Models.ProjectModels import MyModel
from BenchKit.Data.Helpers import get_dataloader
from Datasets.ProjectDatasets import MyChunker
train_chunker = MyChunker()

loss_fn = nn.BCELoss()
model = MyModel(64)
optim = opt.Adam(params=model.parameters(), lr=1e-2)

train_dataset: DataLoader = get_dataloader(train_chunker,"my_ds")
acc = Accelerator()
loss_fn, model, optim, train_dataset = acc.prepare(loss_fn, model, optim, train_dataset)
```

While manually calling and creating an accelerator is fine we recommend you use our custom accelerate methods or our tracker
methods to get one.

#### get_accelerator

If you do not wish to use an external tracking system to generate graphs for your model. Simply call `get accelerator`
this method takes in your models training config (hyperparameters), all the objects you wish to prepare, followed by
any additional accelerator specific arguments as kwargs. These additional arguments can be found [here ↗](https://huggingface.co/docs/accelerate/package_reference/accelerator)

This method will return back the config_id, the accelerator, followed by all the prepared objects


```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_accelerator

tracker_config = {
        "epochs": 10,
        "bs": 16,
        "lr": 1e-2,
        "loss": str(loss_fn)
    }

loss_fn = nn.BCELoss()
model = MyModel(64)
optim = opt.Adam(params=model.parameters(), lr=1e-2)

train_dataset: DataLoader = get_dataloader(train_chunker,"my_ds")

config_id, acc, loss_fn, model, optim,train_dataset = get_accelerator(tracker_config, loss_fn, model, optim, train_dataset)
```
#### Tracker

Trackers are extensions accelerate offers to integrate your code directly with state-of-the-art tracking software,
such as CometML, Wandb, and Tensorboard.

`bench-kit` combines Accelerates tracking integrations with Bench AI's online progress tracking system.

Our methods will return a tracker to you preconfigured with whichever system you wish.

```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_bench_tracker
import torch.nn as nn
import torch.optim as opt
from Models.ProjectModels import MyModel
from BenchKit.Data.Helpers import get_dataloader
from Datasets.ProjectDatasets import MyChunker
from BenchKit.Tracking.Graphers.TimeSeries import TimeSeries
train_chunker = MyChunker()

loss_fn = nn.BCELoss()
model = MyModel(64)
optim = opt.Adam(params=model.parameters(), lr=1e-2)

tracker_config = {
        "epochs": 10,
        "bs": 16,
        "lr": 1e-2
    }

train_loss_graph = TimeSeries("train loss graph",
                                  "train loss",
                                  "epochs",
                                  "loss")

train_dataset: DataLoader = get_dataloader(train_chunker, "my_ds")
config_id, acc, train_dataset, val_dataset, model, loss_fn, optim = get_bench_tracker(tracker_config,
                                                                                 (train_loss_graph,),
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)
```

In this example we use the in house bench tracker. It takes in all the values a regular accelerator takes in, along with
a config dict, and a tuple of graph objects. In this case we use a Time series graph which takes in 4 parameters
("name", line_name / list is of line names, x-axis name, y-axis name). However, many graphing options will be available in house beyond
a time series graph!

##### `log`
To log using your tracker call `.log`
```python filename="TrainScript.py" copy
acc.log({"train loss": 10,
        "graph": "train loss graph"},
        step=1)
```
For the bench tracker the log function is dependent on the graph you happen to use. In this case we want to log to our time series graph
so our dictionary consists of two keys: the line name in this case "train loss" with the y-axis as the value and graph with the name of the graph as the value.
Finally, we use step to send our x-axis value.

To see your graph as your model trains run

```bash copy
bench-kit show-ex
```

<video controls loop muted autoPlay>
  <source src="https://sofadocsbucket.s3.us-west-2.amazonaws.com/assets/Tutorials/train-script/show_graphs.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

From here select your experiment, then appropriate config and the graphs will appear

#### `backward`

Instead of calling `.backwards` on your loss value call it on your accelerator
```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
import torch
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

loss = loss_fn(torch.Tensor([10]), torch.Tensor([100]))
acc.backwards(loss)
```

#### `device`

Hugging Face Accelerate manages device placement for the user as long as all relevant values have been passed into
the prepare function. However, there are some cases where you will create a Tensor that needs to be fed into your
model, and it won't initially be on the right device.

For example
```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
import torch
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

for batch in train_dataset:
    target, inp = batch # on device
    targets = targets.type(torch.FloatTensor) # returns new tensor on CPU
```

In cases like this where your tensor is no longer on the right GPU, transport it back using `accelerate.device`
```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
import torch
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

for batch in train_dataset:
    target, inp = batch # on device
    targets = targets.type(torch.FloatTensor) # returns new tensor on CPU
    targets = targets.to(acc.device) # puts tensor on the right GPU
```

#### Multi GPU Considerations

When training using multiple GPUs each GPU is treated as an individual Process. Meaning if you are using an 8 GPU server
there will be 8 processes of your model training on your server.

This means every line of code in your training script will effectively run `N` times, where `N` is the number of processes. In most cases this is ok
but for some operations it is not preferred.

##### `print`
When printing in most cases you may want to see a message once. To have a print statement not repeat `N` times use `Accelerate.print()`
```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)
acc.print("I ❤️ Bench AI!!!")
```

##### `is_local_main_process`
In general if you want an operation to only take place on one process you can use the command `Accelerate.is_local_main_process`. This will return a
boolean value depending on if the statement is true.

```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

if acc.is_local_main_process:
    acc.print("I am the main")
```

`Accelerate.log` uses this condition under the hood to make sure a log isn't sent for each process.

##### `gather_for_metrics`

When logging loss you don't generally want to log per process. Instead, you will want to record the combined loss of all
processes. In scenarios like this use the `accelerate.gather_for_metrics` method. This will synchronize all tensors on each
process into one Tensor which can now easily be logged

```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker
import torch
acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

for batch in train_dataset:
    loss = loss_fn(torch.Tensor([10]), torch.Tensor([100]))
    full_loss: torch.Tensor = acc.gather_for_metrics(loss)
```

#### `upload_model_checkpoint`
Use `upload_model_checkpoint` when you want to save checkpoints of your model, this method takes in your `Accelerator`
and saves all the objects you prepared with it.

```python filename="TrainScript.py" copy
from BenchKit.Tracking.Tracker import get_tensorboard_tracker

acc, train_dataset, val_dataset, model, loss_fn, optim = get_tensorboard_tracker(tracker_config,
                                                                                 train_dataset,
                                                                                 val_dataset, model,
                                                                                 loss_fn, optim)

upload_model_checkpoint(acc, "test-checkpoint")
```

## Migrate Code
Once you are ready to train your model, you can begin the code migration process. Migrating code saves your code to the cloud, so it can
loaded on any server you want to train with.

Run:
```bash filename="> Terminal" copy
python manage.py migrate-code
```

<video controls loop muted autoPlay>
  <source src="https://sofadocsbucket.s3.us-west-2.amazonaws.com/assets/Tutorials/train-script/migrate-code.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

This command migrates your code with a default version of `one`. This means that if you were to make changes to this code
and were to migrate it, it would overwrite the previous version `one` code you had. All files and folders that were created
with the `start-project` command will be migrated, files not in this category will be left as is.


### Versioning

Versioning becomes extremely useful, when you make changes to your models architecture, data, or training script.
Through versioning you can run multiple experiments of different model versions
and could compare the accuracy of each side by side.

To migrate code with a specific version use this command instead:
```bash filename="> Terminal" copy
python manage.py migrate-code <version: int>
```

To see all your current versions run this command
```bash filename="> Terminal" copy
bench-kit show-vs
```
<video controls loop muted autoPlay>
  <source src="https://sofadocsbucket.s3.us-west-2.amazonaws.com/assets/Tutorials/train-script/show-vs.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>

You can also see all the versions you have for a project by going to your projects experiment page

<video controls loop muted autoPlay>
  <source src="https://sofadocsbucket.s3.us-west-2.amazonaws.com/assets/Tutorials/train-script/Create+Experiment+Site.mp4" type="video/mp4" />
  Your browser does not support the video tag.
</video>







